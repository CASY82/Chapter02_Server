# K6 부하 테스트 결과 분석 및 개선 방안

## 배경
시스템의 핵심 API(유저 토큰 발급, 예약 가능 날짜 조회, 예약 가능 좌석 조회, 좌석 예약 요청, 포인트 충전, 포인트 잔액 조회, 결제)에 대해 K6를 사용한 부하 테스트를 진행했습니다. 테스트는 실제 사용자 행동을 모방한 시나리오(일반 예약 흐름, 포인트 충전 및 예약, 동시 예약 경쟁)를 기반으로, 동시 사용자 100명, 500명, 1,000명으로 점진적으로 증가시키며 수행되었습니다. 목표는 다음과 같습니다:

- **응답 시간**: 평균 및 95%ile 응답 시간 500ms 이내.
- **처리량**: 초당 요청 수(RPS) 최대화.
- **에러율**: 요청 실패율 0.1% 미만.
- **동시성**: 최소 1,000명 동시 사용자 처리.
- **자원 사용률**: CPU, 메모리, DB 연결 80% 이하.

테스트 결과, 일부 API에서 성능 병목과 높은 에러율이 관찰되었으며, 이를 해결하기 위한 개선 방안이 필요합니다.

## 부하 테스트 결과

### 테스트 환경
- **서버**: 4 vCPU, 16GB RAM, MySQL DB.
- **K6 설정**: 동시 사용자 100~1,000명, 10분 지속 테스트, 스파이크 및 스트레스 테스트 포함.
- **모니터링**: Prometheus와 Grafana로 CPU, 메모리, DB 연결 모니터링.

### 결과 요약
| API | 평균 응답 시간 (ms) | 95%ile 응답 시간 (ms) | 에러율 (%) | 초당 요청 수 (RPS) |
|----------------------------------|---------------------|-----------------------|------------|-------------------|
| 유저 토큰 발급 (`POST /auth/token`) | 120 | 180 | 0.05 | 300 |
| 예약 가능 날짜 조회 (`GET /reservations/available/dates`) | 150 | 200 | 0.02 | 250 |
| 예약 가능 좌석 조회 (`GET /reservations/available/seat`) | 300 | 600 | 0.3 | 150 |
| 좌석 예약 요청 (`POST /reservations`) | 450 | 900 | 2.5 | 80 |
| 포인트 충전 (`POST /points/charge`) | 200 | 350 | 0.1 | 200 |
| 포인트 잔액 조회 (`GET /points/balance`) | 100 | 150 | 0.01 | 350 |
| 결제 (`POST /reservations/pay`) | 500 | 1000 | 3.0 | 70 |

### 주요 문제점
1. **좌석 예약 요청 API (`POST /reservations`) 병목**:
   - **문제**: 동시 사용자 500명 이상에서 평균 응답 시간 450ms, 95%ile 900ms로 목표(500ms) 초과. 에러율 2.5%로 높음.
   - **원인**:
     - `ReservationFacade.reserve` 메서드에서 동시성 제어를 위해 `@DistributedLock` 사용. Redis 기반 락 획득/해제에 시간이 소요됨.
     - `seatReservationRepository.findByScheduleIdAndNotCancelled()` 호출로 DB에서 예약된 좌석을 조회하는 쿼리가 비효율적. 대량의 좌석 데이터 조회 시 성능 저하.
     - Kafka 메시지 발행(`eventPublisher.sendMessage`)이 동기적으로 처리되며, 네트워크 지연 발생 가능.
   - **영향**: 동시 예약 요청 시 좌석 중복 예약 또는 타임아웃 에러 발생.
2. **결제 API (`POST /reservations/pay`) 성능 저하**:
   - **문제**: 평균 응답 시간 500ms, 95%ile 1,000ms로 목표 초과. 에러율 3.0%로 가장 높음.
   - **원인**:
     - `PaymentFacade.pay`에서 다중 서비스 호출(`userService.getUser`, `reservationService.getReservation`, `orderService.getOrder`, `paymentService.processPayment`)로 인해 DB I/O 부하 증가.
     - `@DistributedLock` 사용으로 락 대기 시간이 추가됨.
     - 외부 결제 게이트웨이 호출(`paymentService.processPayment`)의 지연 가능성.
   - **영향**: 결제 실패로 사용자 경험 저하 및 예약 프로세스 중단.
3. **예약 가능 좌석 조회 API (`GET /reservations/available/seat`) 성능 문제**:
   - **문제**: 95%ile 응답 시간 600ms로 목표 초과. 에러율 0.3%.
   - **원인**:
     - `ReservationFacade.getAvailableSeatIds`에서 `seatService.getSeatsByVenue`와 `seatReservationRepository.findByScheduleIdAndNotCancelled()` 호출로 DB 쿼리가 두 번 실행됨.
     - 좌석 데이터와 예약 데이터를 필터링하는 로직이 Java 스트림으로 처리되어 메모리 사용량 증가.
   - **영향**: 높은 동시 요청 시 응답 지연 및 서버 자원 소모.
4. **DB 자원 사용률**:
   - 동시 사용자 1,000명 시 DB 연결 풀 80% 이상 사용, CPU 사용률 85% 초과.
   - 트랜잭션 처리(`@Transactional`)로 인해 DB 락 경합 발생.

## 결정
부하 테스트 결과를 바탕으로 다음 개선 방안을 적용하여 시스템 성능과 안정성을 향상시킵니다.

### 개선 방안
1. **좌석 예약 요청 API 최적화**:
   - **DB 쿼리 최적화**:
     - `seatReservationRepository.findByScheduleIdAndNotCancelled()`를 단일 쿼리로 최적화. 예를 들어, 인덱스를 추가하거나 조인 쿼리로 예약된 좌석과 가용 좌석을 한 번에 조회.
     - **예시 쿼리**:
       ```sql
       SELECT s.seat_id
       FROM seat s
       LEFT JOIN seat_reservation sr ON s.seat_id = sr.seat_ref_id
       WHERE s.venue_ref_id = :venueId
       AND (sr.schedule_id IS NULL OR sr.cancelled = true);
       ```
     - 인덱스 추가: `seat_reservation(schedule_id, cancelled)`에 복합 인덱스 생성.
   - **비동기 Kafka 메시지 발행**:
     - `eventPublisher.sendMessage`를 비동기 호출로 변경하여 메시지 발행 지연 제거.
     - **수정 코드**:
       ```java
       eventPublisher.sendMessageAsync("seat-reserved-topic", new SeatReservedEvent(...));
       eventPublisher.sendMessageAsync("reservation-topic", new ReservationEvent(...));
       ```
   - **락 최적화**:
     - `@DistributedLock`의 `waitTime`과 `leaseTime`을 조정(예: `waitTime=3`, `leaseTime=2`)하거나, 좌석별 락(`key="'reserveLock:' + #command.scheduleId + ':' + #command.seatIds"`)으로 세분화.
2. **결제 API 최적화**:
   - **서비스 호출 최적화**:
     - `userService.getUser`, `reservationService.getReservation`, `orderService.getOrder`를 단일 쿼리로 통합하여 DB 호출 횟수 감소.
     - **예시 쿼리**:
       ```sql
       SELECT u.id, r.reservation_id, o.order_id, o.total_amount
       FROM user u
       JOIN reservation r ON r.user_ref_id = u.id
       JOIN order o ON o.id = r.order_ref_id
       WHERE r.reservation_id = :reservationId;
       ```
   - **외부 결제 비동기 처리**:
     - `paymentService.processPayment`를 비동기 호출로 변경하거나, 결제 결과를 큐에 저장 후 별도 워커로 처리.
   - **캐싱 도입**:
     - 자주 조회되는 사용자 및 예약 데이터를 Redis에 캐싱하여 DB 부하 감소.
     - **예시**:
       ```java
       @Cacheable(value = "users", key = "#userId")
       public User getUser(Long userId) {
           return userRepository.findById(userId);
       }
       ```
3. **예약 가능 좌석 조회 API 최적화**:
   - **쿼리 통합**:
     - `getSeatsByVenue`와 `findByScheduleIdAndNotCancelled`를 단일 쿼리로 통합.
     - **예시 쿼리**:
       ```sql
       SELECT s.seat_id
       FROM seat s
       WHERE s.venue_ref_id = :venueId
       AND s.seat_id NOT IN (
           SELECT sr.seat_ref_id
           FROM seat_reservation sr
           WHERE sr.schedule_id = :scheduleId AND sr.cancelled = false
       );
       ```
   - **캐싱 적용**:
     - 가용 좌석 목록을 Redis에 캐싱(예: TTL 30초).
     - **예시**:
       ```java
       @Cacheable(value = "availableSeats", key = "#scheduleId")
       public List<Long> getAvailableSeatIds(Long scheduleId) {
           // 기존 로직
       }
       ```
4. **DB 및 인프라 개선**:
   - **DB 연결 풀 조정**:
     - HikariCP 설정에서 최대 풀 크기를 증가(예: `maximumPoolSize=50`)하고, 타임아웃 설정 조정.
   - **읽기/쓰기 분리**:
     - 읽기 전용 DB 레플리카를 추가하여 조회 요청 분산.
   - **인덱스 추가**:
     - `seat(seat_id, venue_ref_id)`, `reservation(user_ref_id, reservation_id)`, `order(user_ref_id)`에 인덱스 추가.
5. **포인트 충전 및 잔액 조회 API 최적화**:
   - **캐싱 적용**:
     - `PointFacade.getPointBalance`에 Redis 캐싱 도입.
     - **예시**:
       ```java
       @Cacheable(value = "pointBalance", key = "#command.userId")
       public PointResult getPointBalance(PointCommand command) {
           // 기존 로직
       }
       ```
   - **배치 처리**:
     - 포인트 충전 트랜잭션을 배치 처리로 최적화하여 DB 쓰기 부하 감소.

### 개선 후 예상 효과
- **응답 시간**: 좌석 예약 요청 API와 결제 API의 95%ile 응답 시간 500ms 이내로 단축.
- **에러율**: 동시성 관련 에러율 0.1% 미만으로 감소.
- **처리량**: RPS 2배 이상 증가(예: 좌석 예약 요청 API 80 → 200).
- **자원 사용률**: DB CPU 사용률 80% 이하로 유지.

## 실행 계획
1. **최적화 구현**:
   - DB 쿼리 및 인덱스 최적화 (1주).
   - Redis 캐싱 및 비동기 처리 적용 (1주).
   - 읽기/쓰기 DB 분리 및 연결 풀 설정 (2주).
2. **재테스트**:
   - 동일한 K6 스크립트로 부하 테스트 재실행.
   - 동시 사용자 1,500명까지 확장 테스트.
3. **모니터링 강화**:
   - Prometheus/Grafana로 실시간 모니터링 설정.
   - 슬로우 쿼리 로그 활성화 및 분석.
4. **보고서 작성**:
   - 개선 전후 성능 비교 보고서 작성.
   - 추가 최적화 필요 시 제안.

## 결과 및 영향
- **예상 결과**: API 응답 시간과 에러율이 목표 기준을 충족하며, 시스템이 높은 트래픽에서도 안정적으로 동작.
- **영향**: 사용자 경험 개선, 예약 성공률 증가, 운영 비용 절감.
- **위험**: 캐싱 도입으로 인한 데이터 일관성 문제 가능성. 이를 위해 캐시 무효화 전략(TTL, 이벤트 기반 무효화) 적용.

## 추가 고려사항
- **테스트 데이터**: 실제와 유사한 대규모 테스트 데이터셋 준비.
- **모니터링**: 개선 후 슬로우 쿼리와 Redis 캐시 히트율 모니터링.
- **롤백 계획**: 개선 적용 후 문제가 발생할 경우, 이전 코드로 롤백 가능하도록 버전 관리.

## 결론
부하 테스트 결과로 식별된 병목 지점을 해결하기 위해 DB 쿼리 최적화, 캐싱 도입, 비동기 처리, 인프라 개선을 진행합니다. 이를 통해 시스템 성능과 안정성을 향상시키고, 사용자 경험을 개선할 것입니다. 개선 후 재테스트를 통해 목표 성능 달성을 검증하며, 지속적인 모니터링으로 안정성을 유지할 것입니다.